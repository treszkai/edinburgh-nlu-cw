{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 2000\n",
    "train_size = 1000\n",
    "\n",
    "# get the data set vocabulary\n",
    "vocab = pd.read_table(\"../data/vocab.wiki.txt\", header=None, sep=\"\\s+\", index_col=0, names=['count', 'freq'], )\n",
    "num_to_word = dict(enumerate(vocab.index[:vocab_size]))\n",
    "word_to_num = utils.invert_dict(num_to_word)\n",
    "\n",
    "data_train = utils.load_np_dataset('../data/wiki-train.txt')\n",
    "data_test = utils.load_np_dataset('../data/wiki-test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    y = [sent[0] for sent in data]\n",
    "    x = [sent[1:] for sent in data]\n",
    "\n",
    "    x_ = []\n",
    "    for s in x:\n",
    "        x_.append([word_to_num.get(w, word_to_num['UNK'])+1 for w in s])\n",
    "\n",
    "    y_ = []\n",
    "    for l in y:\n",
    "        y_.append(0 if l == 'VBZ' else 1)\n",
    "\n",
    "    x_ = pad_sequences(x_, maxlen=50)\n",
    "    return x_, y_\n",
    "\n",
    "x_train, y_train = process_data(data_train)\n",
    "x_test, y_test = process_data(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 50), (4000, 50))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 50, 200)           400200    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 200)           240800    \n",
      "_________________________________________________________________\n",
      "att (AttentionWithContext)   (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 681,601\n",
      "Trainable params: 681,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Layer\n",
    "from keras.layers import Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Adapted from gist: https://gist.github.com/cbaziotis/7ef97ccf71cbc14366835198c09809d2\n",
    "'''\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "\n",
    "    \n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "        \n",
    "        self.return_attention = return_attention\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        #ait = K.dot(uit, self.u)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number Îµ to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        weighted_input = K.sum(weighted_input, axis=1)\n",
    "        \n",
    "        if self.return_attention:\n",
    "            return [weighted_input, a]\n",
    "        return weighted_input\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #return input_shape[0], input_shape[-1]\n",
    "        output_len = input_shape[-1]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "    \n",
    "\n",
    "def get_model(max_length, vocab_size, trainable=True, \n",
    "              embedding_trainable=True,\n",
    "              hidden_dim=100, return_attention=False):\n",
    "    \n",
    "    '''model = Sequential()\n",
    "    model.add(Embedding(vocab_size, output_dim=256, \n",
    "                        trainable=embedding_trainable))\n",
    "    model.add(LSTM(100, return_sequences=True, trainable=trainable))\n",
    "    model.add(AttentionWithContext(name='att', trainable=trainable))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', trainable=trainable))'''\n",
    "    \n",
    "    input_ = Input(shape=(max_length,), dtype='float32')\n",
    "    input_embed = Embedding(vocab_size+1, output_dim=200, mask_zero=True,\n",
    "                            trainable=embedding_trainable,\n",
    "                            name='embed')(input_)\n",
    "\n",
    "    rnn_encoded = Bidirectional(LSTM(hidden_dim, return_sequences=True),\n",
    "                                name='bidirectional',\n",
    "                                merge_mode='concat',\n",
    "                                trainable=trainable)(input_embed)\n",
    "    '''rnn_encoded = LSTM(hidden_dim, return_sequences=True, \n",
    "                       trainable=trainable)(input_embed)'''\n",
    "\n",
    "    x = AttentionWithContext(name='att', \n",
    "                             return_attention=return_attention,\n",
    "                             trainable=trainable)(rnn_encoded)\n",
    "    att = x\n",
    "    if return_attention:\n",
    "        x, att = x\n",
    "    \n",
    "    if trainable:\n",
    "        dropout = 0.5\n",
    "    else:\n",
    "        dropout = 1.\n",
    "        \n",
    "    drop = Dropout(dropout)(x)\n",
    "    y_hat = Dense(1, activation='sigmoid', trainable=trainable)(drop)\n",
    "    outputs = [y_hat]\n",
    "    \n",
    "    if return_attention:\n",
    "        outputs.append(att)\n",
    "    \n",
    "    model = Model(inputs=input_, outputs=outputs)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = get_model(50, vocab_size)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cp = ModelCheckpoint(\"../models/attention.{epoch:02d}-{val_loss:.2f}.hdf5\",\n",
    "                     monitor='val_loss',\n",
    "                     verbose=0,\n",
    "                     save_best_only=True,\n",
    "                     save_weights_only=True,\n",
    "                     mode='auto')\n",
    "es = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# create a directory if it doesn't already exist\n",
    "if not os.path.exists('../models'):\n",
    "    os.makedirs('../models/')\n",
    "\n",
    "train_size = 25000\n",
    "model.fit(x_train[:train_size], y_train[:train_size], batch_size=16, epochs=10,\n",
    "          callbacks=[cp, es], validation_split=.1)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loading from: ../models/attention.25000.hdf5\n",
      "Loading models\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 50, 200)           400200    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 200)           240800    \n",
      "_________________________________________________________________\n",
      "att (AttentionWithContext)   (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 681,601\n",
      "Trainable params: 0\n",
      "Non-trainable params: 681,601\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 50, 200)           400200    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 200)           240800    \n",
      "_________________________________________________________________\n",
      "att (AttentionWithContext)   [(None, 200), (None, 50)] 40400     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 681,601\n",
      "Trainable params: 0\n",
      "Non-trainable params: 681,601\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weights_file = '../models/attention.25000.hdf5'\n",
    "print('Weights loading from:', weights_file)\n",
    "\n",
    "print('Loading models')\n",
    "pred_model = get_model(50, vocab_size, trainable=False,\n",
    "                      embedding_trainable=False,\n",
    "                      return_attention=False)\n",
    "\n",
    "pred_model.load_weights(weights_file, by_name=True)\n",
    "pred_model.compile(loss='binary_crossentropy',\n",
    "                   optimizer='rmsprop',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "att_model = get_model(50, vocab_size, trainable=False,\n",
    "                      embedding_trainable=False,\n",
    "                      return_attention=True)\n",
    "\n",
    "att_model.load_weights(weights_file, by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  this is when small particles VBP\n",
      "Attention: [  5.16741420e-05   2.16892704e-06   5.68932137e-06   1.90991573e-02\n",
      "   9.80841219e-01]\n",
      "Prediction: VBP\n",
      "Sentence:  his real name VBZ\n",
      "Attention: [ 0.16307743  0.00697914  0.82994342]\n",
      "Prediction: VBP\n",
      "Sentence:  the year VBZ\n",
      "Attention: [ 0.78978533  0.2102142 ]\n",
      "Prediction: VBZ\n",
      "Sentence:  NNP ( lack of NN ) VBZ\n",
      "Attention: [ 0.03721301  0.03612791  0.89390546  0.02222688  0.00153639  0.00898262]\n",
      "Prediction: VBP\n",
      "Sentence:  the picture VBZ\n",
      "Attention: [ 0.60146236  0.3985374 ]\n",
      "Prediction: VBZ\n",
      "Sentence:  the material on caesar VBZ\n",
      "Attention: [ 0.61508089  0.37296653  0.0086765   0.00327595]\n",
      "Prediction: VBZ\n",
      "Sentence:  may my [ brother ] let my NNS VBP\n",
      "Attention: [  4.51011001e-05   1.17332624e-04   7.43764467e-05   1.70000829e-04\n",
      "   6.42177532e-04   9.19625759e-01   2.70856414e-02   5.22388965e-02]\n",
      "Prediction: VBP\n",
      "Sentence:  another negative NN VBZ\n",
      "Attention: [  9.96173918e-01   3.67449073e-04   3.45854554e-03]\n",
      "Prediction: VBZ\n",
      "Sentence:  the town of NNP de NNP VBZ\n",
      "Attention: [  8.56788680e-02   8.89618099e-01   2.35957615e-02   3.79220728e-04\n",
      "   3.06896196e-04   4.20809229e-04]\n",
      "Prediction: VBZ\n",
      "Sentence:  time and time again '' VBZ\n",
      "Attention: [ 0.70650923  0.00183567  0.15682486  0.00217177  0.13264835]\n",
      "Prediction: VBZ\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAABZCAYAAAAesHGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAABNtJREFUeJzt3T+IZWcdxvHn0XVNhixqiJ1FCnXAjRrcjY2F/6JVCkULRQRB7CzUwioGCSlSCDYxQiKy2FiIgkQFtbCSRLITNm7WkBRqsBBxC0mQVTD7WswJGcIdM/POXSc78/k0c7n3nDM/pnj5nnvunNsxRgAA2J/XHfYAAADXIxEFADBBRAEATBBRAAATRBQAwAQRBQAwQUQBAEwQUQAAE0QUAMCEE9M7njgxTp48uc5ZOKKuXLly2CMAR9CZM2cOewSuI1tbW5fHGG9d5zE7+7UvGxsbY3Nzc52zcERduHDhsEcAjiBfW8Z+tN0aY5xd5zFdzgMAmCCiAAAmiCgAgAkiCgBggogCAJggogAAJogoAIAJIgoAYIKIAgCYIKIAACaIKACACSIKAGCCiAIAmCCiAAAmiCgAgAkiCgBggogCAJggogAAJogoAIAJIgoAYIKIAgCYIKIAACaIKACACSIKAGCCiAIAmCCiAAAmiCgAgAkiCgBggogCAJggogAAJogoAIAJIgoAYIKIAgCYIKIAACaIKACACSIKAGCCiAIAmCCiAAAmiCgAgAkiCgBggogCAJggogAAJogoAIAJIgoAYIKIAgCYIKIAACaIKACACSIKAGCCiAIAmCCiAAAmiCgAgAkiCgBggogCAJjQMcbcju0LSZ5Z7zgAuSXJ5cMeAjhyNscYp9Z5wBMH2PeZMcbZtU0CkKTteWsLsG5tz6/7mC7nAQBMEFEAABMOElEPrW0KgJdZW4BrYe1ry/QHywEAjjOX8wAAJrxqRLW9te1TK56/t+2d12YsgNXanmv76cOeA2D6FgdjjHvWOQhw/LRttj9WcPWwZwHYr71eznt924fbXmr7q7Y37jwbbHt/2z+0/X3bb13DeYHr3PLu9tNtH0zyRJLPt3207RNtf9T2pmW7e9o+3vaptg8twQWwcx15ZZt8aVk3nmz747Yby/bn2n637W/a/rHtB9t+fznGuR3H/fiq9Wg3e42odyT5zhjjdJJ/JPnUjl94c5JPJjk9xnhPkvv296cAjqHNJD9I8rEkX0xy5xjjfUnOJ/nass0DY4w7xhi3JbkxyV2HMinwWrWqTX6yrBvvTfJ0tteXl7wlyUeSfDXJI0m+neR0kne3vb3tLUnuzur1aKW9Xs770xjjwvJ4K8mtO157Psm/knyv7c+T/GyPxwSOr+fGGI+1vSvJu5L8dnmj6WSSR5dtPtz260k2ktyc5FK2Fz6AZHWb3Nb2viRvTnJTkl/u2P6RMcZoezHJ38YYF5Ok7aVl37dl9/Vopb1G1L93PH4x22eFSZIxxn/avj/JR5N8JsmXs116ALv55/KzSX49xvjszhfb3pDkwSRnxxh/afvNJDf8f0cEXuNWtcm5JJ8YYzzZ9gtJPrRi+6uv2PdqtnvoxaxYj/6XA9/iYLle+KYxxi+SfCXJ7Qc9JnBsPJbkA23fniRtN9q+My8H0+VljfHfeMBenEry17ZvSPK5fe6723q0q4N8AfFLTiX56XLm2GxfawR4VWOMvy9niz9s+8bl6bvHGM+2fTjJxSR/TvL4IY0IXF++keR3SZ7L9vpxaq877rYeJXl2t33csRwAYII7lgMATBBRAAATRBQAwAQRBQAwQUQBAEwQUQAAE0QUAMAEEQUAMOG/1cvyLshpQV8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk8AAABZCAYAAAAn18DBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAABGZJREFUeJzt3U+oXVcZxuH3a1oqGEnAxAoSuAhFrQ4SktYGQQpKdSaFKg4KDRlJBiJIwZkDKc5Kq6OW1rETiQMH/kEUqVQkaUWSQVChhYIUEhpotVUJXwdnD1Ixuf1yzk2a+Dxwuefuc/Ze68x+rLXZt7o7AAC8N7fd6AkAANxMxBMAwIB4AgAYEE8AAAPiCQBgQDwBAAyIJwCAAfEEADAgngAABm5f5+R9+/b11tbWhqYCsHL69OkbPQXg1nS+u/eve5G14mlrayunTp1adw4A71JVN3oKwK3plU1cxLYdAMCAeAIAGBBPAAAD4gkAYEA8AQAMiCcAgAHxBAAwIJ4AAAbEEwDAgHgCABgQTwAAA+IJAGBAPAEADIgnAIAB8QQAMCCeAAAGxBMAwIB4AgAYEE8AAAPiCQBgQDwBAAyIJwCAAfEEADAgngAABsQTAMCAeAIAGBBPAAAD4gkAYEA8AQAMiCcAgAHxBAAwIJ4AAAbEEwDAgHgCABgQTwAAA+IJAGBAPAEADIgnAIAB8QQAMCCeAAAGxBMAwIB4AgAYEE8AAAPiCQBgQDwBAAyIJwCAAfEEADAgngAABsQTAMCAeAIAGBBPAAAD4gkAYEA8AQAMVHdf+8lVbyQ5t7npAADsmE9094fWvcjta55/rruPrDsJAICdVlWnNnEd23YAAAPiCQBgYN14emYjswAA2Hkb6Za1bhgHAPh/Y9sOAGDgqvFUVXur6sTy+oGq+tn1mRYAwPvTditPe5OcuB4TAQB4v6iqXVd872r3PFXVj5N8JasHYf4nyT+SnE/ymSSnkzzS3V1Vh5M8kWT38v6x7v77xr4BAMAVVNX3kpzv7qeWvx9P8lqSO5N8bfl9sru/u7z/0yQHknwgyVPd/cxy/M2seuZLSb7d3c//r/G2W3n6TpK/dffBJI8lOZTkW0nuSfLxJJ+rqjuS/DDJw919OMmPkjx+bV8fAGDsuSSPJklV3Zbk61nF091J7ktyMMnhqvr88vnjS7McSfLNqvrwcvyDSc5092evFE7J/Anjf+zuV5fJ/SnJVpKLWa1E/aqqkmRXEqtOAMB10d0vV9WFqjqU5K4kLyW5N8mDy+tktTt2d5LfZRVMDy3HDyzHLyS5lOQn2403jad/Xfb60nJ+JTnb3UeH1wIA2JRnkxxL8tGsdsG+kOT73f305R+qqgeSfDHJ0e7+Z1X9NqvtuyR5u7svbTfQdtt2byTZ7h/onUuyv6qOLpO6o6o+vd3AAAAbdDLJl7NacfrF8nO8qnYnSVV9rKo+kmRPkteXcPpkkvunA1115am7L1TV76vqTJK3sto//O/P/LuqHk7yg6ras1zzySRnp5MBALgWS4/8JsnFZfXol1X1qSQvLLcVvZnkkSQ/T/KNqvpzVgtAf5iO5QnjAMBNb7lR/MUkX+3uv+zkWJ4wDgDc1KrqniR/TfLrnQ6nxMoTAMCIlScAgAHxBAAwIJ4AAAbEEwDAgHgCABgQTwAAA+8A9EjKVK2eBfUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAABZCAYAAADB/guFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAABfBJREFUeJzt3U2IXWcZB/D/k5SYVGulpnXhQiiCCwVLElFBF+lON1oRCwYsVaTion7uRCiIIkJURMGvalGqYKWtguCiQVpXahz7EdHsigsXGrTYmGhi8riYi4yTvDM3mZt7505/v9Wde95zzsO8c8/7n3Pee051dwAAuNSuRRcAALBdCUoAAAOCEgDAgKAEADAgKAEADAhKAAADghIAwICgBAAwICgBAAxcN6sNVVXv2rVzc5c7mC+vAwcOLLoEtmBlZWXRJbAFjp1sY6e6++bNGtWs/oh3797de/funcm2tiMf9uV15syZRZfAFuzZs2fRJbAF58+fX3QJXKWdfPIjSS5evPjb7j60Wbud/VsAANgCQQkAYEBQAgAYEJQAAAYEJQCAAUEJAGBAUAIAGBCUAAAGBCUAgAFBCQBgQFACABgQlAAABgQlAIABQQkAYEBQAgAYEJQAAAYEJQCAAUEJAGBAUAIAGBCUAAAGBCUAgAFBCQBgQFACABgQlAAABgQlAIABQQkAYEBQAgAYEJQAAAYEJQCAAUEJAGBAUAIAGBCUAAAGBCUAgAFBCQBgQFACABgQlAAABgQlAIABQQkAYEBQAgAYEJQAAAYEJQCAAUEJAGBAUAIAGBCUAAAGBCUAgAFBCQBgQFACABgQlAAABgQlAIABQQkAYEBQAgAYEJQAAAYEJQCAgeru2Wyo6vkkJ2eyMeZtf5JTiy6Cq6b/lpv+W176brm9prtv2KzRdTPc4cnuPjTD7TEnVXVc3y0v/bfc9N/y0nfLraqOT9POpTcAgAFBCQBgYJZB6Zsz3Bbzpe+Wm/5bbvpveem75TZV/81sMjcAwE7j0hsAwMCmQamquqqOrvn5k1V13+T1fVV1pqpuWbP89JrXF6rqyao6UVUPVdX1M64fdrS1n6crXO+Bqnr3rOvh2qiqe6vqD1X14KJr4VJbGQdZftOcUfp3kndV1f7B8lNJPjFYdra7b+vu1yU5l+RDV1Ej11hV7auqx6tq96JrgReoDyd5e3cfWXQhXNZWxkG2oaraU1VPVNWmt0maJij9J6sTnj42WP6dJHdW1U2bbOeXSV49xf6Yv/cnebi7Lyy6EC6vql5SVceqaqWqnqmqd6xZ9r6qerqqnqqq719m3c9MzjC51L4NVNXHJ2fZT1TVR6vq60luTfLTqhodZ1msWY2DbBPdfS7JsSR3btZ22gPn15IcqaobL7PsdFb/SD4yWnmS2N6W5Jkp98d8HUnyk0UXwYb+leSO7j6Q5HCSo7XqtUk+leT27n591n0Oq+oLSW5Jcnd3X5x30fy/qjqY5O4kb0zypiQfTPKNJH9Ocri7v7TA8tjYlsZBtqVHszr+bWiqoNTd/0jyvST3Dpp8JcldVfXSde/vq6onkxxP8qck90+zP+anqvYkubW7n110LWyoknyuqp5O8liSVyZ5RZLbk/y4u08lSXf/bc06n07ysu6+p329dbt4S5JHuvuf3X06ycNJ3rrgmpjCFsZBtq8TSd6wWaMreYTJl5OsJPnu+gXd/VxV/SCr19nXOtvdt13BPpi//UmeW3QRbOpIkpuTHOzu81X1bJK9WQ1QoxD0myQHq+qmdQGKxalFF8CWXM04yDbV3Req6lxV3dDdz4/aTT1nYXKg/VGSDwyafDHJPZnt8+O49s5mdcBle7sxyV8mIelwkldN3j+W5D1V9fIkWTdH4udJPp/kZ1W16YMfmYsnkryzqq6vqhcnuSOr8zdZAsbBHelFWZ3aMHSlkzuPZvUMxCUmp/4fmeyUJdHdf0+yu6qEpe3twSSHJg9xPJLkj0nS3b9P8tkkj1fVU1k9UP9Pdz+U5FtZnSi8b74ls153ryR5IMmvk/wqybe7+3cLLYorZRzcISb/YP61u89v2M7UBarq/iQ/7O7HFl0LAMzD5F5zb+7uDW/t4OvCJMlXk9y16CIAYI7emyme9yYokcmp/1+44SQALwSTb3w/2t0nN23r0hsAwOU5owQAMCAoAQAMCEoAAAOCEgDAgKAEADDwXwAfZQENJ/2/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAABZCAYAAAD8bGrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAABMJJREFUeJzt3U+oZnUdx/HPN51ASRCZCdzoUy6kScoY8S/hQJt2EU1EFLSJCBdRi8CwbVC0cOHCv4hCCkG40Y2J9FeCaSZGK2sWkVEQ9I/IXBjJt8WcS7dh5t773Pu9MzS8Xpv73Oc8v3O+3NWbc85zbnV3AADYu7dd7AEAAC4VwgoAYIiwAgAYIqwAAIYIKwCAIcIKAGCIsAIAGCKsAACGCCsAgCGX72XxwYMHe7VaDY0CcMbJkycv9gjApekv3X1oPw+wp7BarVY5ceLE1CwASZKqutgjAJem3+33AVwKBAAYIqwAAIYIKwCAIcIKAGCIsAIAGCKsAACGCCsAgCHCCgBgiLACABgirAAAhggrAIAhwgoAYIiwAgAYIqwAAIYIKwCAIcIKAGCIsAIAGCKsAACGCCsAgCHCCgBgiLACABgirAAAhggrAIAhwgoAYIiwAgAYIqwAAIYIKwCAIcIKAGCIsAIAGCKsAACGCCsAgCHCCgBgiLACABgirAAAhggrAIAhwgoAYIiwAgAYIqwAAIYIKwCAIcIKAGCIsAIAGCKsAACGCCsAgCHCCgBgiLACABgirAAAhggrAIAhwgoAYIiwAgAYIqwAAIYIKwCAIcIKAGCIsAIAGFLdvfvFVa8nOT03DgDAvrmxu6/azwNcvsf1p7v7lpFJAAD2UVWd2O9juBQIADBEWAEADNlrWD0yMgUAwP7b927Z083rAAD8l0uBAABDtgyrqrq6qu5ZXh+tqucuzFgAADtTVY9V1eEtth+tqjsvxCzbnbG6Osk9F2IQAIDd6O7PdverW3zkaJK1wqqqLtvNLNuF1deT3FBVp5J8M8k7quo7VfXrqnqqqmo5+JGq+kFVnayq56vq2t0MAwBwPlW1Whrkyap6ZWmSK6vq+1V1y/KZD1fVz6rq5ap6sapWST6f5EtVdaqqPlhVT1TVsU37/efy82hVfa+qnk7y8+W9T1fV8WXtw9sF13ZhdW+S33T3zUm+nOQDSb6Y5HCSdye5q6oOJHkgybHuPpLk8SRfW/NvBQCwEzcmeaS735fkH9l0Za2qDiV5NMnHuvv9ST7e3a8leSjJ/d19c3f/aJv935rkvu4+XFXvSfKJJHctLfRWkk9ttXjdJ68f7+4/LMOfSrJK8vckNyV5YTmBdVmSP665XwCAnfh9d7+0vP5Wki9s2nZ7kh9292+TpLv/tov9H99Yn+RDSY4k+enSOFck+dNWi9cNqzc3vX5rWV9Jftndd6y5LwCAdZ39nKjNv9c5tp/Lv7NctVtua3r7pm1vnLW/J7v7KzsdbrtLga8n2e6fFZ5Ocqiq7lgGPFBV793pAAAAa7huozmSfDLJjzdt+0mSu6vqXUlSVdcs75/dM6/lzJmoJPlIkgPnOdaLSY5V1Ts39ldV12813JZh1d1/TfJSVf0iZ25eP9dn/pXkWJJvVNXLSU5lzTvvAQB26FdJPlNVryS5JsmDGxu6+89JPpfkmaVJvr1sejbJRzduXs+Z+7DurqrjSW7L/56lyqb9vZrkq0m+uxzvhSRbfkHPk9cBgP8Lyzf8nuvumy7yKOflyesAAEOcsQIAGOKMFQDAEGEFADBEWAEADBFWAABDhBUAwBBhBQAw5D88aM20CGvXvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize_attention(text, att_weights):\n",
    "    \n",
    "    activation_map = np.transpose(np.expand_dims(att_weights, axis=1))\n",
    "\n",
    "    #plt.clf()\n",
    "    f = plt.figure(figsize=(10, 1))\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "    # add image\n",
    "    i = ax.imshow(activation_map, aspect='auto',\n",
    "                  interpolation='nearest', cmap='gray')\n",
    "\n",
    "    # add colorbar\n",
    "    #cbaxes = f.add_axes([0.2, 0.3, 0.6, 0.03])\n",
    "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "    cbar.ax.set_xlabel('Probability', labelpad=2)\n",
    "\n",
    "    # add labels\n",
    "    ax.set_ylim(0,.1)\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_yticks([], [])\n",
    "    #ax.set_yticks(range(output_length))\n",
    "    #ax.set_yticklabels(predicted_text[:output_length])\n",
    "\n",
    "    ax.set_xticks(range(len(text)))\n",
    "    ax.set_xticklabels(text)\n",
    "\n",
    "    #_ = ax.set_xlabel('Sentence')\n",
    "\n",
    "    # add grid and legend\n",
    "    #ax.grid()\n",
    "    # ax.legend(loc='best')\n",
    "\n",
    "    #f.savefig(os.path.join(HERE, 'attention_maps', text.replace('/', '')+'.pdf'), bbox_inches='tight')\n",
    "    #f.show()\n",
    "\n",
    "\n",
    "np.random.seed(11)\n",
    "samples = np.random.choice(x_test.shape[0], 1000)\n",
    "counts = [0, 0, 0, 0, 0, 0]\n",
    "for i in samples:\n",
    "    text = data_test[i][1:]\n",
    "    if len(text) > 10:\n",
    "        continue\n",
    "    \n",
    "    pred, att = att_model.predict(np.expand_dims(x_test[i], axis=0))\n",
    "    pred_str = 'VBP' if pred.ravel()[0] < .5 else 'VBZ'\n",
    "    \n",
    "    att = att[0,-len(text):].ravel()\n",
    "    verb_dist = len(att) - np.argmax(att)\n",
    "    \n",
    "    if verb_dist < len(counts) and counts[verb_dist] < 2:\n",
    "        counts[verb_dist] += 1\n",
    "    \n",
    "        print('Sentence: ', *[w for w in text], data_test[i][0])\n",
    "        print('Attention:', att)\n",
    "        print('Prediction:', pred_str)\n",
    "\n",
    "        visualize_attention(text, att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 8s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5808403358459473, 0.90549999999999997]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pred_model.evaluate(x_test, y_test, batch_size=16)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlu]",
   "language": "python",
   "name": "conda-env-nlu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
